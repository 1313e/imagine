{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGINE tutorial 1 \n",
    "\n",
    "## The basic elements of an IMAGINE pipeline\n",
    "\n",
    "#### ...imagine using a toy model for the field...\n",
    "#### ...and a corresponding toy simulator...\n",
    "\n",
    "In this tutorial, we focus on introducing the basic building blocks in IMAGINE package and how to use them for assembling a Bayesian analysis pipeline\n",
    "\n",
    "We will use mock data with only two independent free parameters. First we need to generate the mock data. Then we will assemble all elements needed for the IMAGINE pipeline, execute the pipeline and investigate its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The mock data are designed to naively mimic Faraday depth, which is affected linearly by (Galactic) magnetic field and thermal electron density. As a function of position $x$, we define a constant coherent magnetic field component $a_0$ and a random magnetic field component which is drawn from a Gaussian distribution with standard deviation $b_0$. The electron density is given by a $\\cos(x)$ with arbitrary scaling. The mock data values we get are related to the Faraday depth of a background source at some arbitrary distance: \n",
    "\n",
    "\n",
    "$ signal(x) = \\left[1+\\cos(x)\\right] \\times \\mathcal{G}(\\mu=a_0,\\sigma=b_0;seed=s)\\,{\\mu\\rm G\\,cm}^{-3} , \\; x \\in [0,2\\pi\\,\\rm kpc]$\n",
    "\n",
    "where $\\{a_0,b_0\\}$ is the 'physical' parameter set, and $s$ represents the seed for random variable generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The purpose is not to fit the exact signal, since it includes a stochastic component, but to fit the amplitude of the signal and of the variations around it.  So this is fitting the strength of the coherent field $a_0$ and the amplitude of the random field $b_0$. \n",
    "\n",
    "With mock data and its (co)variance matrix, we shall assemble the IMAGINE pipeline, execute it and examine its results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging as log\n",
    "from astropy.table import Table\n",
    "from astropy import units as u\n",
    "## visualize posterior with 3rd party corner package (pip install corner)\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imagine as img\n",
    "\n",
    "# call after importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Preparation of mock data\n",
    "\n",
    "In calculating the mock data values, we introduce noise as:\n",
    "\n",
    "$ data(x) = signal(x) + noise(x) $\n",
    "\n",
    "For simplicity, we propose a simple gaussian noise with mean zero and a standard deviation $e$:\n",
    "\n",
    "$ noise(x) = \\mathcal{G}(\\mu=0,\\sigma=e) $ .\n",
    "\n",
    "We will assume that we have 10 points in the x-direction, in the range $(0, 2\\pi)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=4</i>\n",
       "<table id=\"table140063819623056\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>meas</th><th>err</th><th>x</th><th>y</th><th>z</th><th>other</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>16.4217790817552</td><td>0.1</td><td>0.01</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "<tr><td>7.172468731201507</td><td>0.1</td><td>0.7059094785755097</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "<tr><td>-3.2254947821460433</td><td>0.1</td><td>1.4018189571510193</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "<tr><td>0.27949334758966465</td><td>0.1</td><td>2.0977284357265287</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       "        meas          err           x             y       z     other \n",
       "      float64       float64      float64       float64 float64 float64\n",
       "------------------- ------- ------------------ ------- ------- -------\n",
       "   16.4217790817552     0.1               0.01     0.0     0.0    42.0\n",
       "  7.172468731201507     0.1 0.7059094785755097     0.0     0.0    42.0\n",
       "-3.2254947821460433     0.1 1.4018189571510193     0.0     0.0    42.0\n",
       "0.27949334758966465     0.1 2.0977284357265287     0.0     0.0    42.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = 3. # true value of a\n",
    "b0 = 6. # true value of b\n",
    "e = 0.1 # std of gaussian measurement error\n",
    "s = 233 # seed fixed for signal field\n",
    "\n",
    "size = 10 # data size in measurements\n",
    "x = np.linspace(0.01,2.*np.pi-0.01,size) # where the observer is looking at\n",
    "\n",
    "np.random.seed(s) # set seed for signal field\n",
    "\n",
    "signal = (1+np.cos(x)) * np.random.normal(loc=a0,scale=b0,size=size)\n",
    "\n",
    "fd = signal + np.random.normal(loc=0.,scale=e,size=size)\n",
    "\n",
    "\n",
    "data = Table({'meas' : fd, \n",
    "              'err': np.ones_like(fd)*e,\n",
    "              'x': x,\n",
    "              'y': np.zeros_like(fd),\n",
    "              'z': np.zeros_like(fd),\n",
    "              'other': np.ones_like(fd)*42\n",
    "              })\n",
    "data[:4] # Shows the first 4 points in tabular form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data need to be converted to an IMAGINE compatible format. To do this, we first create `TabularDataset` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "fd_units = u.microgauss*u.cm**-3\n",
    "\n",
    "mockDataset = img.dataset.TabularDataset(data, name='test', \n",
    "                                         data_column='meas', \n",
    "                                         coordinates_type='cartesian',\n",
    "                                         x_column='x', y_column='y', \n",
    "                                         z_column='z', error_column='err',\n",
    "                                         units=fd_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simply explains to imagine how to read the tabular dataset (note that the 'other' column is ignored). \n",
    "The units of the dataset are represented using [astropy.units](https://docs.astropy.org/en/stable/units/) objects.\n",
    "Coordinates can be either `cartesian` as in this example, which requires specifying columns for $x$, $y$ and $z$ in $\\rm kpc$, or  `galactic`, which requires setting the arguments `lat_column` and `lon_column` both in degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be loaded onto `Measurements` and `Covariances` object, which are subclasses of `ObservableDict`. These objects allow one to supply multiple datasets to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = img.Measurements() # create empty Measrurements object\n",
    "mock_data.append(dataset=mockDataset)\n",
    "\n",
    "mock_cov = img.Covariances() # create empty Covariance object\n",
    "mock_cov.append(dataset=mockDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset object creates a standard key for each appended dataset. In our case, there is only one key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test', 'nan', 'tab', 'nan')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(mock_data.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the mock data as well as the $\\cos(x)$ function that is the underlying variation.  \n",
    "\n",
    "The property `Measurements.global_data` extracts arrays from the `Observable` object which is hosted inside the `ObservableDict` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, mock_data[keys[0]].global_data[0], marker='.', label='signal')\n",
    "plt.plot(x,(1+np.cos(x))*a0,'r--',label='$1+\\cos(x)$')\n",
    "plt.xlabel('x'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variance in the signal is highest where the $\\cos(x)$ is also strongest. This is the way we expect the Faraday depth to work, since a fluctuation in the strength of $\\mathbf B$ has a larger effect on the RM when $n_e$ also happens to be higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pipeline assembly\n",
    "\n",
    "Now that we have generated mock data, there are several steps to set up the pipeline to estimate the input parameters.  We need to define field models, simulators, likelihoods and priors.\n",
    "\n",
    "1) Coordinate grid: the coordinate grid on which the fields will be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_d_grid = img.UniformGrid(box=[[0,2*np.pi]*u.kpc,\n",
    "                                 [0,0.001]*u.kpc,\n",
    "                                 [0,0.001]*u.kpc],\n",
    "                             resolution=[30,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Field models: in this test we will use two field models: one for the thermal electrons, and another one for the magneticfield.\n",
    "\n",
    "`CosThermalElectronDensity` corresponds to a toy model for electron density with the form: $n_e(x,y,z) = n_0 [1+\\cos (a x + \\alpha)][1+\\cos (b y + \\beta)][1+\\cos(c y + \\gamma)]$. We include this in the pipeline instantiating and adjusting the associated *Field Factory*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagine.fields.test_field as testFields\n",
    "ne_factory = testFields.CosThermalElectronDensity_Factory(grid=one_d_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set and check the default parameter values in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n0': <Quantity 1. 1 / cm3>,\n",
       " 'a': <Quantity 1. rad / kpc>,\n",
       " 'b': <Quantity 0. rad / kpc>,\n",
       " 'c': <Quantity 0. rad / kpc>,\n",
       " 'alpha': <Quantity 0. rad>,\n",
       " 'beta': <Quantity 1.57079633 rad>,\n",
       " 'gamma': <Quantity 1.57079633 rad>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_factory.default_parameters= {'a': 1*u.rad/u.kpc,\n",
    "                                'beta':  np.pi/2*u.rad, \n",
    "                                'gamma': np.pi/2*u.rad}\n",
    "ne_factory.default_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now similarly define the magnetic field, using the `NaiveGaussianMagneticField` which constructs a \"naive\" random field (i.e. the magnitude of $x$, $y$ and $z$ components of the field are drawn from a Gaussian distribution **without** imposing *zero divergence*, thus *do not use this for serious applications*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_factory = testFields.NaiveGaussianMagneticField_Factory(grid=one_d_grid)\n",
    "B_factory.active_parameters = ('a0','b0')\n",
    "B_factory.priors ={'a0': img.FlatPrior(interval=[-10,10]*u.microgauss),\n",
    "                   'b0': img.FlatPrior(interval=[0,10]*u.microgauss)}\n",
    "B_factory.default_parameters = {'a0':a0*u.microgauss, 'b0':b0*u.microgauss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory_list = [ne_factory, B_factory]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Simulators: For this tutorial, we use a customized TestSimulator which simply computes the quantity: $t(x,y,z) = B_y\\,n_e\\,$,i.e. the contribution at one specific point to the Faraday depth.\n",
    "\n",
    "The simulator is inialized with the mock Measurements defined before, which allows it to know what is the correct format for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.simulators.test_simulator import TestSimulator\n",
    "simer = TestSimulator(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = B_factory.generate(ensemble_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne = ne_factory.generate(ensemble_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Likelihoods: IMAGINE provides the `Likelihood` class with `EnsembleLikelihood` and `SimpleLikelihood` as two options.  The `SimpleLikelihood` is what you expect, computing a single $\\chi^2$ from the difference of the simulated and the measured datasets.  The `EnsembleLikelihood` is how IMAGINE handles a signal which itself includes a stochastic component, e.g., what we call the Galactic variance.  This likelihood module makes use of a finite ensemble of simulated realizations and uses their mean and covariance to compare them to the measured dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = img.EnsembleLikelihood(mock_data, mock_cov) # initialize likelihood with measured info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct and run the pipeline itself.\n",
    "\n",
    "As you will see below, the `Pipeline` class takes as input arguments all elements we defined in the lines above to start calculating.\n",
    "\n",
    "The current two pipelines here are based on different samplers:\n",
    "\n",
    "1. `MultinestPipeline` : is quite old but fast, has its core in Fortran.\n",
    "2. `DynestyPipeline`: is new and purely in Python, extremely well documented, but it's slower\n",
    "\n",
    "Since we are using the `EnsembleLikelihood`, we also need to define an ensemble size, i.e. the number of simulations with the same input parameters that will be generated at each sample. Different realizations of the random magnetic field will render all simulated data sets different; their variance is an estimate of the Galactic variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate 100 realizations at each sample\n",
    "ensemble_size = 10  \n",
    "## Define the pipeline using the MultiNest sampler, giving it the required elements\n",
    "pipe = img.MultinestPipeline(simer, factory_list, likelihood, ensemble_size)\n",
    "## Set its random seed with a positive integer, or 0 to start randomly from the system clock.  \n",
    "pipe.random_type = 'free'\n",
    "## Set some controller parameters that are specific to pyMultiNest.  \n",
    "pipe.sampling_controllers = {'n_iter_before_update': 1,\n",
    "                             'n_live_points': 600,\n",
    "                             'verbose': True,\n",
    "                             'resume': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Pipeline roll out with Multinest\n",
    "\n",
    "The IMAGINE pipeline use variables which all range within $[0,1]$ internally. This conversion from physical parameters (with arbitrary extrema) and parameters (in range $[0,1]$) is done automatically in the factories. The function `unity_mapper` reads the information in the samples and then then maps the output parameters back to their physical values.\n",
    "\n",
    "This actually runs the pipeline and will take a few seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the results, which consist of a set of sampled points in the likelihood space.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.tools.carrier_mapper import unity_mapper\n",
    "samples = results['samples']  # load sample points\n",
    "\n",
    "## convert from pipeline-internal (0-1) values into physical parameters\n",
    "for i, param in enumerate(pipe.active_parameters): \n",
    "    low, high = pipe.active_ranges[param]\n",
    "    for j, sample in enumerate(samples[:,i]):\n",
    "        samples[j,i] = unity_mapper(sample, low, high)\n",
    "\n",
    "##  See https://corner.readthedocs.io/en/latest/pages/sigmas.html about contour levels.  \n",
    "##  \"Contours are shown at 0.5, 1, 1.5, and 2 sigma\" by default\n",
    "##  according to https://pypi.org/project/corner/1.0.1/, but I want 1, 2, and 3.\n",
    "sigmas=np.array([1.,2.,3.])\n",
    "levels=1-np.exp(-0.5*sigmas*sigmas)\n",
    "\n",
    "# Visualize with a corner plot\n",
    "figure = corner.corner(samples[:, :len(pipe.active_parameters)],\n",
    "                      range=[0.99]*len(pipe.active_parameters),\n",
    "                      quantiles=[0.02, 0.5, 0.98],\n",
    "                      labels=pipe.active_parameters,\n",
    "                      show_titles=True,\n",
    "                      title_kwargs={\"fontsize\": 15},\n",
    "                      color='steelblue',\n",
    "                      truths=[a0,b0],\n",
    "                      truth_color='firebrick',\n",
    "                      plot_contours=True,\n",
    "                      hist_kwargs={'linewidth': 2},\n",
    "                      label_kwargs={'fontsize': 15},\n",
    "                      levels=levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Pipeline roll out with a Dynesty\n",
    "\n",
    "Now, use the Dynesty sampler instead of MultiNest.\n",
    "The only difference at the frontend is the sampler-dependent\n",
    "controlling parameters. \n",
    "One advantage of Dynesty is that it provides an informative \n",
    "progress bar under the cell executing it, as you can see.\n",
    "\n",
    "(This run takes a bit longer, tens of seconds, likely because\n",
    "the sampler needs to be optimized better.)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.pipelines.dynesty_pipeline import DynestyPipeline\n",
    "\n",
    "pipe_dynesty = DynestyPipeline(simer, factory_list, likelihood, ensemble_size)\n",
    "pipe_dynesty.random_type = 'free'\n",
    "pipe_dynesty.sampling_controllers = {'nlive': 400} \n",
    "\n",
    "results_dynesty = pipe_dynesty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = results_dynesty['samples']\n",
    "for i, param in enumerate(pipe_dynesty.active_parameters): \n",
    "    low, high = pipe_dynesty.active_ranges[param]\n",
    "    for j, sample in enumerate(samples[:,i]):\n",
    "        samples[j, i] = unity_mapper(sample, low, high)\n",
    "# corner plot\n",
    "figure = corner.corner(samples[:, :len(pipe_dynesty.active_parameters)],\n",
    "                       range=[0.99]*len(pipe_dynesty.active_parameters),\n",
    "                       quantiles=[0.02, 0.5, 0.98],\n",
    "                       labels=pipe_dynesty.active_parameters,\n",
    "                       show_titles=True,\n",
    "                       title_kwargs={\"fontsize\": 15},\n",
    "                       color='steelblue',\n",
    "                       truths=[a0,b0],\n",
    "                       truth_color='firebrick',\n",
    "                       plot_contours=True,\n",
    "                       hist_kwargs={'linewidth': 2},\n",
    "                       label_kwargs={'fontsize': 15})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum: a simple convergence check\n",
    "\n",
    "The mock data was generated with a fixed random seed, while in the Bayesian analysis time-thread dependent seeds are adopted. Therefore, it is interesting to check if different executions are consistent.  In other words, when you start the sampler at different places, does it always converge on the same region of parameter space?  Let's see what happens when we run it five times and just overplot histograms of the outputs to see if they all look the same.  There are more rigorous tests, of course, that we have done, but they take longer.  This can be done in a few minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "repeat = 5\n",
    "\n",
    "for i in range(repeat):\n",
    "    tmp = pipe()\n",
    "    asamp = tmp['samples'][:,0]\n",
    "    bsamp = tmp['samples'][:,1]\n",
    "    plt.hist(asamp, 30, histtype='step', stacked=True, \n",
    "             fill=True, color='firebrick', alpha=0.1)\n",
    "    plt.hist(bsamp, 30, histtype='step', stacked=True,\n",
    "             fill=True,label='b',color='steelblue',alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This ends tutorial 1. \n",
    "\n",
    "The python script for tutorial 1 can be found in [li_multinest](https://github.com/IMAGINE-Consortium/imagine/blob/mpi/examples/test_examples/lisimulator_multinest.py) and [li_dynesty](https://github.com/IMAGINE-Consortium/imagine/blob/mpi/examples/test_examples/lisimulator_dynesty.py)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (imagine)",
   "language": "python",
   "name": "imagine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
