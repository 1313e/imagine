{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic elements of an IMAGINE pipeline\n",
    "\n",
    "In this tutorial, we focus on introducing the basic building blocks of the IMAGINE package and how to use them for assembling a Bayesian analysis pipeline.\n",
    "\n",
    "We will use mock data with only two independent free parameters. First, we will generate the mock data. Then we will assemble all elements needed for the IMAGINE pipeline, execute the pipeline and investigate its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mock data are designed to \"naively\" mimic Faraday depth, which is affected linearly by the (Galactic) magnetic field and thermal electron density. As a function of position $x$, we define a constant coherent magnetic field component $a_0$ and a random magnetic field component which is drawn from a Gaussian distribution with standard deviation $b_0$. The electron density is assumed to be independently known and given by a $\\cos(x)$ with arbitrary scaling. \n",
    "The mock data values we get are related to the Faraday depth of a background source at some arbitrary distance: \n",
    "\n",
    "$$ signal(x) = \\left[1+\\cos(x)\\right] \\times \\mathcal{G}(\\mu=a_0,\\sigma=b_0;seed=s)\\,{\\mu\\rm G\\,cm}^{-3} , \\; x \\in [0,2\\pi]\\,\\rm kpc$$\n",
    "\n",
    "where $\\{a_0,b_0\\}$ is the 'physical' parameter set, and $s$ represents the seed for random variable generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The purpose is not to fit the exact signal, since it includes a stochastic component, but to fit the amplitude of the signal and of the variations around it.  So this is fitting the strength of the coherent field $a_0$ and the amplitude of the random field $b_0$.  With these mock data and its (co)variance matrix, we shall assemble the IMAGINE pipeline, execute it and examine its results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging as log\n",
    "from astropy.table import Table\n",
    "import astropy.units as u\n",
    "import corner\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import imagine as img\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Preparing the mock data\n",
    "\n",
    "In calculating the mock data values, we introduce noise as:\n",
    "\n",
    "$$ data(x) = signal(x) + noise(x) $$\n",
    "\n",
    "For simplicity, we propose a simple gaussian noise with mean zero and a standard deviation $e$:\n",
    "\n",
    "$$ noise(x) = \\mathcal{G}(\\mu=0,\\sigma=e) $$ .\n",
    "\n",
    "We will assume that we have 10 points in the x-direction, in the range $[0, 2\\pi]\\,\\rm kpc$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=4</i>\n",
       "<table id=\"table140165166416464\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>meas</th><th>err</th><th>x</th><th>y</th><th>z</th><th>other</th></tr></thead>\n",
       "<thead><tr><th>uG / cm3</th><th></th><th></th><th></th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>16.4217790817552</td><td>0.1</td><td>0.01</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "<tr><td>7.172468731201507</td><td>0.1</td><td>0.7059094785755097</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "<tr><td>-3.2254947821460433</td><td>0.1</td><td>1.4018189571510193</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "<tr><td>0.27949334758966465</td><td>0.1</td><td>2.0977284357265287</td><td>0.0</td><td>0.0</td><td>42.0</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=4>\n",
       "        meas          err           x             y       z     other \n",
       "      uG / cm3                                                        \n",
       "      float64       float64      float64       float64 float64 float64\n",
       "------------------- ------- ------------------ ------- ------- -------\n",
       "   16.4217790817552     0.1               0.01     0.0     0.0    42.0\n",
       "  7.172468731201507     0.1 0.7059094785755097     0.0     0.0    42.0\n",
       "-3.2254947821460433     0.1 1.4018189571510193     0.0     0.0    42.0\n",
       "0.27949334758966465     0.1 2.0977284357265287     0.0     0.0    42.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a0 = 3. # true value of a in microgauss\n",
    "b0 = 6. # true value of b in microgauss\n",
    "e = 0.1 # std of gaussian measurement error\n",
    "s = 233 # seed fixed for signal field\n",
    "\n",
    "size = 10 # data size in measurements\n",
    "x = np.linspace(0.01,2.*np.pi-0.01,size) # where the observer is looking at\n",
    "\n",
    "np.random.seed(s) # set seed for signal field\n",
    "\n",
    "signal = (1+np.cos(x)) * np.random.normal(loc=a0,scale=b0,size=size)\n",
    "\n",
    "fd = signal + np.random.normal(loc=0.,scale=e,size=size)\n",
    "\n",
    "# We load these to an astropy table for illustration/visualisation\n",
    "data = Table({'meas' : u.Quantity(fd, u.microgauss*u.cm**-3),\n",
    "              'err': np.ones_like(fd)*e,\n",
    "              'x': x,\n",
    "              'y': np.zeros_like(fd),\n",
    "              'z': np.zeros_like(fd),\n",
    "              'other': np.ones_like(fd)*42\n",
    "              })\n",
    "data[:4] # Shows the first 4 points in tabular form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data need to be converted to an IMAGINE compatible format. To do this, we first create `TabularDataset` object, \n",
    "which helps importing dictionary-like dataset onto IMAGINE.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_units = u.microgauss*u.cm**-3\n",
    "\n",
    "mockDataset = img.observables.TabularDataset(data, name='test', \n",
    "                                             data_col='meas', \n",
    "                                             err_col='err')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lines simply explain how to read the tabular dataset (note that the 'other' column is ignored): `name` contains the type of observable we are using (here, we use 'test', it could also be 'sync' for synchrotron observables (e.g, Stokes parameters), 'fd' for Faraday Depth, etc. The `data_column` argument specifies the key or name of the column containing the relevant measurement. Coordinates can be either `cartesian` as in this example, which requires specifying columns for $x$, $y$ and $z$ in $\\rm kpc$, or  `galactic`, which requires setting the arguments `lat_column` and `lon_column` both in degrees.\n",
    "The units of the dataset are represented using [astropy.units](https://docs.astropy.org/en/stable/units/) objects and must be supplied (the Simulator will later check whether these are adequate and automatically convert the data to other units if needed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be loaded onto `Measurements` and `Covariances` object, which are subclasses of `ObservableDict`. These objects allow one to supply multiple datasets to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = img.observables.Measurements() # create empty Measrurements object\n",
    "mock_data.append(dataset=mockDataset)\n",
    "\n",
    "mock_cov = img.observables.Covariances() # create empty Covariance object\n",
    "mock_cov.append(dataset=mockDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset object creates a standard key for each appended dataset. In our case, there is only one key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test', 'None', 'tab', None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(mock_data.keys())\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the mock data as well as the $1+\\cos(x)$ function that is the underlying variation.  \n",
    "\n",
    "The property `Measurements.global_data` extracts arrays from the `Observable` object which is hosted inside the `ObservableDict` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, mock_data[keys[0]].global_data[0], marker='.', label='signal')\n",
    "plt.plot(x,(1+np.cos(x))*a0,'r--',label='$1+\\cos(x)$')\n",
    "plt.xlabel('x'); plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the variance in the signal is highest where the $\\cos(x)$ is also strongest. This is the way we expect the Faraday depth to work, since a fluctuation in the strength of $\\mathbf B$ has a larger effect on the RM when $n_e$ also happens to be higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pipeline assembly\n",
    "\n",
    "Now that we have generated mock data, there are a few steps to set up the pipeline to estimate the input parameters.  We need to specify: a grid, Field Factories, Simulators, and Likelihoods.\n",
    "\n",
    "### Setting the coordinate grid\n",
    "\n",
    "Fields in IMAGINE represent models of any kind of physical field -- in this particular tutorial, we will need a magnetic field and thermal electron density. \n",
    "\n",
    "The Fields are evaluated on a grid of coordinates, represented by a `img.Grid` object. Here we exemplify how to produce a *regular cartesian* grid. To do so, we need to specify the values of the coordinates on the 6 extremities of the box (i.e. the minimum and maximum value for each coordinate), and the resolution over each dimension.  \n",
    "\n",
    "For this particular artificial example, we actually only need one dimension, \n",
    "so we set the resolution to 1 for $y$ and $z$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_d_grid = img.fields.UniformGrid(box=[[0,2*np.pi]*u.kpc,\n",
    "                                         [0,0]*u.kpc,\n",
    "                                         [0,0]*u.kpc],\n",
    "                                    resolution=[30,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Field Factory list\n",
    "\n",
    "A particular realisation of a model for a physical field is represented within IMAGINE by a *Field* object, which, given set of parameters, evaluates the field for over the grid.  \n",
    "\n",
    "A *Field Factory* is an associated piece of infrastructure used by the Pipeline to produce new Fields. It is a Factory object that needs to be initialized and supplied to the Pipeline. This is what we will illustrate here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine import fields\n",
    "ne_factory = fields.CosThermalElectronDensityFactory(grid=one_d_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous line instantiates `CosThermalElectronDensityFactory` with the previously defined Grid object. This Factory allows the Pipeline to produce\n",
    "`CosThermalElectronDensity` objects. These correspond to a toy model for electron density with the form: \n",
    "$$n_e(x,y,z) = n_0 [1+\\cos (a x + \\alpha)][1+\\cos (b y + \\beta)][1+\\cos(c y + \\gamma)]\\,. $$ \n",
    "\n",
    "We can set and check the default parameter values in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n0': <Quantity 1. 1 / cm3>,\n",
       " 'a': <Quantity 1. rad / kpc>,\n",
       " 'b': <Quantity 0. rad / kpc>,\n",
       " 'c': <Quantity 0. rad / kpc>,\n",
       " 'alpha': <Quantity 0. rad>,\n",
       " 'beta': <Quantity 1.57079633 rad>,\n",
       " 'gamma': <Quantity 1.57079633 rad>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_factory.default_parameters= {'a': 1*u.rad/u.kpc,\n",
    "                                'beta':  np.pi/2*u.rad, \n",
    "                                'gamma': np.pi/2*u.rad}\n",
    "ne_factory.default_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ne_factory.active_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For `ne_factory`, no active parameters were set. This means that the Field will be always evaluated using the specified default parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now similarly define the magnetic field, using the `NaiveGaussianMagneticField` which constructs a \"naive\" random field (i.e. the magnitude of $x$, $y$ and $z$ components of the field are drawn from a Gaussian distribution **without** imposing *zero divergence*, thus *do not use this for serious applications*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_factory = fields.NaiveGaussianMagneticFieldFactory(grid=one_d_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differently from the case of `ne_factory`, in this case we would like to make the parameters active. All individual components of the field are drawn from a Gaussian distribution with mean $a_0$ and standard deviation $b_0$. To set these parameters as active we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_factory.active_parameters = ('a0','b0')\n",
    "B_factory.priors ={'a0': img.priors.FlatPrior(interval=[-5,5]*u.microgauss),\n",
    "                   'b0': img.priors.FlatPrior(interval=[0,10]*u.microgauss)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lines above we chose uniform (flat) priors for both parameters within the above specified ranges. Any active parameter must have a Prior distribution specified.\n",
    "\n",
    "Once the two FieldFactory objects are prepared, they put together in a list which is later supplied to the Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory_list = [ne_factory, B_factory]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Simulator\n",
    "\n",
    "For this tutorial, we use a customized TestSimulator which simply computes the quantity: $t(x,y,z) = B_y\\,n_e\\,$,i.e. the contribution at one specific point to the Faraday depth.\n",
    "\n",
    "The simulator is inialized with the mock Measurements defined before, which allows it to know what is the correct format for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagine.simulators import TestSimulator\n",
    "simer = TestSimulator(mock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the Likelihood\n",
    "IMAGINE provides the `Likelihood` class with `EnsembleLikelihood` and `SimpleLikelihood` as two options.  The `SimpleLikelihood` is what you expect, computing a single $\\chi^2$ from the difference of the simulated and the measured datasets.  The `EnsembleLikelihood` is how IMAGINE handles a signal which itself includes a stochastic component, e.g., what we call the Galactic variance.  This likelihood module makes use of a finite ensemble of simulated realizations and uses their mean and covariance to compare them to the measured dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = img.likelihoods.EnsembleLikelihood(mock_data, mock_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Running the pipeline\n",
    "\n",
    "Now we have all the necessary components available to run our pipeline. This can be done through a `Pipeline` object, which interfaces with some algorithm to sample the likelihood space accounting for the prescribed prior distributions for the parameters. \n",
    "\n",
    "IMAGINE comes with a range of samplers coded as different Pipeline classes, most of which are based on the nested sampling approach. \n",
    "In what follows we will use the [UltraNest](https://johannesbuchner.github.io/UltraNest/) sampler as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMAGINE takes care of stochastic fields by evaluating an ensemble of random realisations for each selected point in the parameter space, and computing the associated covariance (i.e. estimating the [Galactic variance](https://ui.adsabs.harvard.edu/abs/2010MNRAS.401.1013J/abstract)). We can set this up through the `ensemble_size` argument.\n",
    "\n",
    "Now we are ready to initialize our final pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = img.pipelines.UltranestPipeline(simulator=simer, \n",
    "                                           factory_list=factory_list, \n",
    "                                           likelihood=likelihood, \n",
    "                                           ensemble_size=150,\n",
    "                                           chains_directory=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chains_directory` keyword may contain a path where the chains generated by the sampler are saved in the sampler's native format (if the sampler supports this). If this argument is absent or set to `None`, a temporary directory will be created in the *current working directory*, and will be automatically removed when  together the Pipeline object becomes out of scope (e.g. when one runs `del pipeline` or exits the script/notebook).  After initialization, we can check this choice inspecting the `chains_directory` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/x1313e/stack/Custom Python Packages/imagine/tutorials/imagine_chains_l87uhkb1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.chains_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The property `sampling_controllers` allows one to send sampler-specific parameters to the chosen Pipeline. \n",
    "Each IMAGINE Pipeline object will have slightly different sampling controllers, which can be found in the specific Pipeline's docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.sampling_controllers = {'max_ncalls': 500, 'min_num_live_points': 50}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `UltranestPipeline`, for example, allows one to set a limit on the number of likelihood evaluations using the sampling controller `'max_ncalls'`). This is convenient for quick tests and examples (as this tutorial). Similar functionality is available in the `DynestyPipeline` under the name `'max_call'` (and also `'max_call_init'`/`'max_call_batch'` for dynamic nested sampling).\n",
    "\n",
    "In a production run, however, one would rather set the target estimated uncertainty in the model evidence and/or target posterior uncertainty, and allow the model to converge to it. This can be done using the following sampling controllers (do check individual docs for details):\n",
    "\n",
    "In `UltranestPipeline` this is done using `'dlogZ'` for target log-evidence error and `'dKL'` for target posterior error. In `MultinestPipeline` one can only controll the target log-evidence error, using `'evidence_tolerance'`.  In `DynestyPipeline` the log-evidence error can be controlled using: `'dlogz'` (also `'dlogz_init'`), but the sampler can also try to optimize the estimate of the posterior while running in the *dynamic* mode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we *finally* can run the pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] PointStore: have 0 items\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ultranest:PointStore: have 0 items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ultranest] Sampling 50 live points from prior ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ultranest:Sampling 50 live points from prior ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8fdfdaa4a88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/stack/Custom Python Packages/imagine/imagine/pipelines/pipeline.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stack/Custom Python Packages/imagine/imagine/pipelines/ultranest_pipeline.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m             **init_params)\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviz_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrun_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_samples_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/site-packages/ultranest/integrator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, update_interval_iter_fraction, update_interval_ncall, log_interval, show_status, viz_callback, dlogz, dKL, frac_remain, Lepsilon, min_ess, max_iters, max_ncalls, max_num_improvement_loops, min_num_live_points, cluster_num_live_points)\u001b[0m\n\u001b[1;32m   1786\u001b[0m             \u001b[0mcluster_num_live_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcluster_num_live_points\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0mshow_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_status\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m             \u001b[0mviz_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mviz_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m         ):\n\u001b[1;32m   1790\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/site-packages/ultranest/integrator.py\u001b[0m in \u001b[0;36mrun_iter\u001b[0;34m(self, update_interval_iter_fraction, update_interval_ncall, log_interval, dlogz, dKL, frac_remain, Lepsilon, min_ess, max_iters, max_ncalls, max_num_improvement_loops, min_num_live_points, cluster_num_live_points, show_status, viz_callback)\u001b[0m\n\u001b[1;32m   1849\u001b[0m             \u001b[0mviz_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_default_viz_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1851\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_widen_roots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_num_live_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0mLlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/site-packages/ultranest/integrator.py\u001b[0m in \u001b[0;36m_widen_roots\u001b[0;34m(self, nroots)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncall\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_live_points_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m                 \u001b[0mactive_logl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloglike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mactive_logl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_live_points_missing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mactive_logl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_live_points_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/site-packages/ultranest/utils.py\u001b[0m in \u001b[0;36mvectorized\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"\"\" vectorized version of function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mvectorized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/site-packages/ultranest/utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvectorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;34m\"\"\" vectorized version of function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mvectorized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stack/Custom Python Packages/imagine/imagine/pipelines/pipeline.py\u001b[0m in \u001b[0;36m_core_likelihood\u001b[0;34m(self, cube)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mobservables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;31m# add up individual log-likelihood terms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mcurrent_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stack/Custom Python Packages/imagine/imagine/simulators/simulator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, field_list)\u001b[0m\n\u001b[1;32m    414\u001b[0m                                     \u001b[0mrealization_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                                     output_units=self.output_units[key])\n\u001b[0;32m--> 416\u001b[0;31m                 \u001b[0msims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_units\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/stack/Custom Python Packages/imagine/imagine/observables/observable_dict.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, name, new_data, plain)\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0mHEALPix\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0msky\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \"\"\"\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@ observable_dict::Simulations::append'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36mdebug\u001b[0;34m(msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m         \u001b[0mbasicConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m     \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36mdebug\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Houston, we have a %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"thorny problem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m         \"\"\"\n\u001b[0;32m-> 1365\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misEnabledFor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEBUG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/imagine/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36misEnabledFor\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \"\"\"\n\u001b[1;32m   1618\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m             \u001b[0m_acquireLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When one runs the pipeline it returns a results dictionary object in the native format of the chosen sampler. \n",
    "Alternatively, after running the pipeline object, the results can also be accessed through its attributes, \n",
    "which are standard interfaces (i.e. all pipelines should work in the same way). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparing different models, the quantity of interest is the *model evidence* or *marginal likelihood*. After a run, this can be easily accessed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('log evidence:', round(pipeline.log_evidence,4))\n",
    "print('log evidence error:', round(pipeline.log_evidence_err,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick-and-dirty summary of the constraints on the parameters can be (nicely) displayed using the `posterior_report()` method. \n",
    "\n",
    "(The \"real\" parameter values were $a_0=3\\mu \\rm G$ and $b_0=6\\mu \\rm G$.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nParameter constraints:')\n",
    "pipeline.posterior_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar information can be accessed through property `posterior_summary`, which returns a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.posterior_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, however, one would (should) prefer to work directly on the samples produced by the sampler. \n",
    "A table containing the parameter values of the samples generated can be accessed through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output"
    ]
   },
   "outputs": [],
   "source": [
    "samples = pipeline.samples\n",
    "samples[:3] # Displays only first 3 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions of samples approximate the posterior distribution, below this is plotted with the help of the [corner](https://corner.readthedocs.io/en/latest/) library, whcih also shows the best-fit values and $1\\sigma$ and $2\\sigma$ contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_corner(samp):  \n",
    "\n",
    "    ##  See https://corner.readthedocs.io/en/latest/pages/sigmas.html about contour levels.  \n",
    "    ##  \"Contours are shown at 0.5, 1, 1.5, and 2 sigma\" by default\n",
    "    ##  according to https://pypi.org/project/corner/1.0.1/, but I want 1, 2, and 3.\n",
    "    sigmas=np.array([1.,2.,3.])\n",
    "    levels=1-np.exp(-0.5*sigmas*sigmas)\n",
    "\n",
    "    # Visualize with a corner plot\n",
    "    figure = corner.corner(np.vstack([samp.columns[0].value, samp.columns[1].value]).T,\n",
    "                           range=[0.99]*len(samp.colnames),\n",
    "                           quantiles=[0.02, 0.5, 0.98],\n",
    "                           labels=samp.colnames,\n",
    "                           show_titles=True,\n",
    "                           title_kwargs={\"fontsize\": 12},\n",
    "                           color='steelblue',\n",
    "                           truths=[a0,b0],\n",
    "                           truth_color='firebrick',\n",
    "                           plot_contours=True,\n",
    "                           hist_kwargs={'linewidth': 2},\n",
    "                           label_kwargs={'fontsize': 10},\n",
    "                           levels=levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_corner(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can, of course, choose other plotting/analysis routines. Below, the use of [seaborn](http://seaborn.pydata.org) is exemplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_samples_seaborn(samp):\n",
    "    \n",
    "    def show_truth_in_jointplot(jointplot, true_x, true_y, color='r'):\n",
    "        for ax in (jointplot.ax_joint, jointplot.ax_marg_x):\n",
    "            ax.vlines([true_x], *ax.get_ylim(), colors=color)\n",
    "        for ax in (jointplot.ax_joint, jointplot.ax_marg_y):\n",
    "            ax.hlines([true_y], *ax.get_xlim(), colors=color)\n",
    "\n",
    "    snsfig = sns.jointplot(*samp.colnames, data=samp.to_pandas(), kind='kde')\n",
    "    snsfig.plot_joint(sns.scatterplot, linewidth=0, marker='.', color='0.3')\n",
    "    show_truth_in_jointplot(snsfig, a0, b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_seaborn(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seeds and convergence checks\n",
    "\n",
    "The pipeline relies on random numbers in multiple ways. \n",
    "The Monte Carlo sampler will draw randomly chosen points in the parameter space duing its exploration (in the specific case of *nested sampling* pipelines, these are drawn from the prior distributions). Also, while evaluating the fields at each point, random realisations of the stochastic fields are generated.\n",
    "\n",
    "It is possible to control the behaviour of the random seeding of an IMAGINE pipeline through the attribute `master_seed`. This attribute has two uses: it is passed to the sampler, ensuring that its behaviour is reproducible; and it is also used to generate a fresh list of new random seeds to each stochastic field that is evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.master_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the master seed is fixed and set to 1, but you can alter its value before running the pipeline. \n",
    "\n",
    "One can also change the seeding behaviour through the `random_type` attribute. There are three allowed options for this:\n",
    "\n",
    "* 'controllable' - the `master_seed` is constant and a re-running the pipeline should lead to the exact same results (default);\n",
    "* 'free' - on each execution, a new `master_seed` is drawn (using numpy.randint);\n",
    "* 'fixed' - this mode is for debugging purposes. The `master_seed` is fixed, as in the 'controllable' case, however each individual stochastic field receives the exact same list of ensemble seeds every time (while in the `controllable` these are chosen \"randomly\" at run-time). Such choice can be inspected using `pipeline.ensemble_seeds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now check whether different executions of the pipeline are generating consistent results.\n",
    "To do so, we run it five times and just overplot histograms of the outputs to see if they all look the same. There are more rigorous tests, of course, that we have done, but they take longer.  The following can be done in a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "# Adjust the random behaviour\n",
    "pipeline.random_type = 'free'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 4))\n",
    "repeat = 5\n",
    "\n",
    "for i in range(repeat):   \n",
    "    if i>0: \n",
    "        print('-'*60+'\\nRun {}/{}'.format(i+1,repeat))\n",
    "        # Re-runs the pipeline!\n",
    "        _ = pipeline()\n",
    "    \n",
    "    for j, param in enumerate(pipeline.samples.columns):\n",
    "        samp = pipeline.samples[param]\n",
    "        axs[j].hist(samp.value, alpha=0.4, bins=30, label=pipeline.master_seed)\n",
    "        axs[j].set_title(param)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].legend(title='seed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script example\n",
    "\n",
    "A script version of this tutorial can be found in the [examples directory](https://github.com/IMAGINE-Consortium/imagine/tree/master/examples/basic_pipeline.py).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
